lars                   package:lars                    R Documentation

_F_i_t_s _L_e_a_s_t _A_n_g_l_e _R_e_g_r_e_s_s_i_o_n, _L_a_s_s_o _a_n_d _I_n_f_i_n_i_t_e_s_i_m_a_l _F_o_r_w_a_r_d _S_t_a_g_e_w_i_s_e
_r_e_g_r_e_s_s_i_o_n _m_o_d_e_l_s

_D_e_s_c_r_i_p_t_i_o_n:

     These are all variants of Lasso, and provide the entire sequence
     of coefficients and fits, starting from zero, to the least squares
     fit.

_U_s_a_g_e:

     lars(x, y, type = c("lasso", "lar", "forward.stagewise", "stepwise"), 
         trace = FALSE, normalize = TRUE, intercept = TRUE, Gram, eps = .Machine$double.eps, max.steps, use.Gram = TRUE)
     
_A_r_g_u_m_e_n_t_s:

       x: matrix of predictors

       y: response

    type: One of "lasso", "lar", "forward.stagewise" or "stepwise". The
          names can be abbreviated to any unique substring. Default is
          "lasso".

   trace: If TRUE, lars prints out its progress

normalize: If TRUE, each variable is standardized to have unit L2 norm,
          otherwise it is left alone. Default is TRUE.

intercept: if TRUE, an intercept is included in the model (and not
          penalized), otherwise no intercept is included. Default is
          TRUE.

    Gram: The X'X matrix; useful for repeated runs (bootstrap) where a
          large X'X stays the same.

     eps: An effective zero

max.steps: Limit the number of steps taken; the default is ‘8 * min(m,
          n-intercept)’, with m the number of variables, and n the
          number of samples.  For ‘type="lar"’ or ‘type="stepwise"’,
          the maximum number of steps is ‘min(m,n-intercept)’. For
          ‘type="lasso"’ and especially ‘type="forward.stagewise"’,
          there can be many more terms, because although no more than
          ‘min(m,n-intercept)’ variables can be active during any step,
          variables are frequently droppped and added as the algorithm
          proceeds. Although the default usually guarantees that the
          algorithm has proceeded to the saturated fit, users should
          check.

use.Gram: When the number m of variables is very large, i.e. larger
          than N, then you may not want LARS to precompute the Gram
          matrix. Default is use.Gram=TRUE

_D_e_t_a_i_l_s:

     LARS is described in detail in Efron, Hastie, Johnstone and
     Tibshirani (2002). With the "lasso" option, it computes the
     complete lasso solution simultaneously for ALL values of the
     shrinkage parameter in the same computational cost as a least
     squares fit. A "stepwise" option has recently been added to LARS.

_V_a_l_u_e:

     A "lars" object is returned, for which print, plot, predict, coef
     and summary methods exist.

_A_u_t_h_o_r(_s):

     Brad Efron and Trevor Hastie

_R_e_f_e_r_e_n_c_e_s:

     Efron, Hastie, Johnstone and Tibshirani (2003) "Least Angle
     Regression" (with discussion) _Annals of Statistics_; see also
     <URL:
     http://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf>.
     Hastie, Tibshirani and Friedman (2002) Elements of Statistical
     Learning, Springer, NY.

_S_e_e _A_l_s_o:

     print, plot, summary and predict methods for lars, and cv.lars

_E_x_a_m_p_l_e_s:

     data(diabetes)
     par(mfrow=c(2,2))
     attach(diabetes)
     object <- lars(x,y)
     plot(object)
     object2 <- lars(x,y,type="lar")
     plot(object2)
     object3 <- lars(x,y,type="for") # Can use abbreviations
     plot(object3)
     detach(diabetes)
     

